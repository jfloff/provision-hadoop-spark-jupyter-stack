---
- hosts: all
  become: no
  any_errors_fatal: true
  gather_facts: no
  vars_files:
    - vars.yaml

  # https://medium.com/codex/running-a-multi-node-hadoop-cluster-257068e5f276
  tasks:
    - name: Remove hadoop folders
      file:
        path: "{{ item }}"
        state: absent
        force: yes
      with_items:
        - "{{ hadoop_home_dir }}"
        - "{{ hadoop_hdfs_data_dir }}"
        - "{{ hadoop_namenode_dir }}"
        - "{{ hadoop_pid_dir }}"
        - "{{ hadoop_temp_dir }}"

    - name: Download Hadoop {{hadoop_version}}
      run_once: true
      delegate_to: 127.0.0.1
      ansible.builtin.get_url:
        url: https://archive.apache.org/dist/hadoop/common/hadoop-{{hadoop_version}}/hadoop-{{hadoop_version}}.tar.gz
        dest: /tmp/hadoop-{{hadoop_version}}.tar.gz

    - name: Deploy Hadoop bundle to remote nodes
      copy:
        src: /tmp/hadoop-{{hadoop_version}}.tar.gz
        dest: "{{ default_install_dir }}/hadoop-{{hadoop_version}}.tar.gz"
        # checksum: "sha256:{{hadoop_version_sha256}}"

    - name: Unarchive hadoop
      ansible.builtin.unarchive:
        src: "{{ default_install_dir }}/hadoop-{{hadoop_version}}.tar.gz"
        dest: "{{ default_install_dir }}"
        remote_src: yes

    - name: Create HDFS data dir
      file:
        path: "{{ item }}"
        state: directory
        mode: "g+rw"
      with_items:
        - "{{ hadoop_hdfs_data_dir }}"
        - "{{ hadoop_namenode_dir }}"
        - "{{ hadoop_pid_dir }}"
        - "{{ hadoop_temp_dir }}"

    - name: Update Hadoop core-site configuration
      ansible.builtin.template:
        src: templates/hadoop/core-site.xml.j2
        dest: "{{ hadoop_conf_dir }}/core-site.xml"

    - name: Update Hadoop env configuration
      ansible.builtin.template:
        src: templates/hadoop/hadoop-env.sh.j2
        dest: "{{ hadoop_conf_dir }}/hadoop-env.sh"

    - name: Update Hadoop hdfs site configuration
      ansible.builtin.template:
        src: templates/hadoop/hdfs-site.xml.j2
        dest: "{{ hadoop_conf_dir }}/hdfs-site.xml"

    - name: Update Hadoop mapred site configuration
      ansible.builtin.template:
        src: templates/hadoop/mapred-site.xml.j2
        dest: "{{ hadoop_conf_dir }}/mapred-site.xml"

    - name: Update Hadoop workers configuration
      ansible.builtin.template:
        src: templates/hadoop/workers.j2
        dest: "{{ hadoop_conf_dir }}/workers"

    - name: Update Hadoop yarn configuration
      ansible.builtin.template:
        src: templates/hadoop/yarn-site.xml.j2
        dest: "{{ hadoop_conf_dir }}/yarn-site.xml"

- hosts: hdfs_namenode
  become: true
  vars_files:
    - vars.yaml

  tasks:
    - name: Format HDFS
      shell: >
        {{ hadoop_home_dir }}/bin/hdfs namenode -format -force
      args:
        executable: /bin/bash
      when: (hdfs_format | default(false)) | bool

    - name: Ensure 127.0.1.1 is commented
      lineinfile:
        path: /etc/hosts
        regexp: '^127\.0\.1\.1'
        line: '# \g<0>'
        backrefs: yes

    - name: Add datanodes entries to /etc/hosts
      lineinfile:
        path: /etc/hosts
        line: "{{ hostvars[item]['ansible_host'] }} {{ item }}"
        state: present
        create: yes
      loop: "{{ groups['hdfs_datanodes'] }}"

- hosts: hdfs_datanodes
  become: true
  tasks:
    - name: Get the namenode host and IP
      set_fact:
        namenode_ip: "{{ hostvars[groups['hdfs_namenode'][0]]['ansible_host'] }}"
        namenode_host: "{{ groups['hdfs_namenode'][0] }}"

    - name: Add namenode entry to /etc/hosts
      lineinfile:
        path: /etc/hosts
        line: "{{ namenode_ip }} {{ namenode_host }}"
        state: present
        create: yes