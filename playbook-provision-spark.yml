---
- hosts: all
  become: no
  any_errors_fatal: true
  gather_facts: no
  vars_files:
      - vars.yaml

  # https://medium.com/codex/running-a-multi-node-hadoop-cluster-257068e5f276
  # https://medium.com/codex/setting-up-a-multi-node-apache-spark-cluster-on-apache-hadoop-and-apache-hive-412764ab6881
  tasks:
    - name: Download Spark {{hadoop_version}}
      run_once: true
      delegate_to: 127.0.0.1
      ansible.builtin.get_url:
        url: https://archive.apache.org/dist/spark/spark-{{spark_version}}/spark-{{spark_version}}-bin-hadoop3.tgz
        dest: /tmp/spark-{{spark_version}}-bin-hadoop3.tgz

    - name: Deploy Spark bundle to remote nodes
      copy:
        src: /tmp/spark-{{spark_version}}-bin-hadoop3.tgz
        dest: "{{ default_install_dir }}/spark-{{spark_version}}-bin-hadoop3.tgz"
        # checksum: "sha256:{{spark_version_sha256}}"

    - name: Unarchive Spark
      ansible.builtin.unarchive:
        src: "{{ default_install_dir }}/spark-{{spark_version}}-bin-hadoop3.tgz"
        dest: "{{ default_install_dir }}"
        remote_src: yes

    - name: Ensure YARN Shuffle Service JAR is present
      copy:
        src: "{{ default_install_dir }}/spark-{{ spark_version }}-bin-hadoop3/yarn/spark-{{ spark_version }}-yarn-shuffle.jar"
        dest: "{{ default_install_dir }}/hadoop-{{ hadoop_version }}/share/hadoop/yarn/spark-{{ spark_version }}-yarn-shuffle.jar"
        mode: '0644'
        remote_src: yes

    - name: Create Spark data dir
      file:
        path: "{{ item }}"
        state: directory
        mode: "g+rw"
      with_items:
        - "{{ spark_local_dirs }}"
        - "{{ java_local_dirs }}"

    - name: Configure Spark with HDFS Hadoop core-site configuration
      ansible.builtin.template:
        src: templates/hadoop/core-site.xml.j2
        dest: "{{spark_conf_dir}}/core-site.xml"

    - name: Configure Spark with HDFS Hadoop hdfs site configuration
      ansible.builtin.template:
        src: templates/hadoop/hdfs-site.xml.j2
        dest: "{{spark_conf_dir}}/hdfs-site.xml"

    - name: Configure Spark with HDFS Hadoop workers configuration
      ansible.builtin.template:
        src: templates/hadoop/workers.j2
        dest: "{{spark_conf_dir}}/workers"

    - name: Configure Spark with HDFS Hadoop yarn configuration
      ansible.builtin.template:
        src: templates/hadoop/yarn-site.xml.j2
        dest: "{{spark_conf_dir}}/yarn-site.xml"

    - name: Configure Spark scheduler
      ansible.builtin.template:
        src: templates/spark/fairscheduler.xml.j2
        dest: "{{spark_conf_dir}}/fairscheduler.xml"

    - name: Configure Spark log4j2
      ansible.builtin.template:
        src: templates/spark/log4j2.properties.j2
        dest: "{{spark_conf_dir}}/log4j2.properties"

    - name: Configure Spark metrics
      ansible.builtin.template:
        src: templates/spark/metrics.properties.j2
        dest: "{{spark_conf_dir}}/metrics.properties"

    - name: Configure Spark defaults
      ansible.builtin.template:
        src: templates/spark/spark-defaults.conf.j2
        dest: "{{spark_conf_dir}}/spark-defaults.conf"

    - name: Configure Spark envs
      ansible.builtin.template:
        src: templates/spark/spark-env.sh.j2
        dest: "{{spark_conf_dir}}/spark-env.sh"
